{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Federated learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CqC3GxLKeL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52b8ffbf-2eb5-47e5-a4df-fe76695b5ba2"
      },
      "source": [
        "!pip install syft==0.2.0a2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft==0.2.0a2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/92/1d41de2cbb196dc315e083228ad41308107e7a298e7f547106daa756ee0c/syft-0.2.0a2-py3-none-any.whl (337kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 2.9MB/s \n",
            "\u001b[?25hCollecting lz4>=2.1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/81/011fef8766fb0ef681037ad6fee96168ee03a864464986cbaa23e5357704/lz4-3.0.2-cp36-cp36m-manylinux2010_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 9.4MB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/23/d418c9102d4054d19d57ccf0aca18b7c1c1f34cc0a136760b493f78ddb06/torchvision-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 20.0MB/s \n",
            "\u001b[?25hCollecting zstd>=1.4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/46/c17843364277eef48437c1ad8d083600c82afab23b6bc8281eae247d0277/zstd-1.4.4.0.tar.gz (469kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 61.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.0a2) (1.1.1)\n",
            "Collecting msgpack>=0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/a8/e01fea81691749044a7bfd44536483a296d9c0a7ed4ec8810a229435547c/msgpack-0.6.2-cp36-cp36m-manylinux1_x86_64.whl (249kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 59.2MB/s \n",
            "\u001b[?25hCollecting torch==1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/50a05de5337f7a924bb8bd70c6936230642233e424d6a9747ef1cfbde353/torch-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (773.1MB)\n",
            "\u001b[K     |████████████████████████████████| 773.1MB 23kB/s \n",
            "\u001b[?25hCollecting websocket-client>=0.56.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 63.1MB/s \n",
            "\u001b[?25hCollecting websockets>=7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.0a2) (1.17.5)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft==0.2.0a2) (1.6.0)\n",
            "Collecting flask-socketio>=3.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/66/44/edc4715af85671b943c18ac8345d0207972284a0cd630126ff5251faa08b/Flask_SocketIO-4.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.1->syft==0.2.0a2) (6.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.1->syft==0.2.0a2) (1.12.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft==0.2.0a2) (2.10.3)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft==0.2.0a2) (7.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft==0.2.0a2) (0.16.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft==0.2.0a2) (1.1.0)\n",
            "Collecting python-socketio>=4.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/e0/71c90fbfc534108d0869ff5f92c16e4bc9b1347439b9022e815c03ff4193/python_socketio-4.4.0-py2.py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft==0.2.0a2) (1.1.1)\n",
            "Collecting python-engineio>=3.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/16/66b05477d6057238e2fc1f8cfb1dfd0b3adad1351c30ad20934f09db5891/python_engineio-3.11.2-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: zstd\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zstd: filename=zstd-1.4.4.0-cp36-cp36m-linux_x86_64.whl size=1131222 sha256=02678832132dadb7c3677eca680fe1167e032710adb02aebe4859408b4cb9d35\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/0d/5a/3c2ccf5522d1cd3ecdeb2af8c9889179d7a204376b1d5c042d\n",
            "Successfully built zstd\n",
            "Installing collected packages: lz4, torch, torchvision, zstd, msgpack, websocket-client, websockets, python-engineio, python-socketio, flask-socketio, syft\n",
            "  Found existing installation: torch 1.3.1\n",
            "    Uninstalling torch-1.3.1:\n",
            "      Successfully uninstalled torch-1.3.1\n",
            "  Found existing installation: torchvision 0.4.2\n",
            "    Uninstalling torchvision-0.4.2:\n",
            "      Successfully uninstalled torchvision-0.4.2\n",
            "  Found existing installation: msgpack 0.5.6\n",
            "    Uninstalling msgpack-0.5.6:\n",
            "      Successfully uninstalled msgpack-0.5.6\n",
            "Successfully installed flask-socketio-4.2.1 lz4-3.0.2 msgpack-0.6.2 python-engineio-3.11.2 python-socketio-4.4.0 syft-0.2.0a2 torch-1.3.0 torchvision-0.4.1 websocket-client-0.57.0 websockets-8.1 zstd-1.4.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZeGk9lDKi8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d5b72165-678c-4a3c-c7db-b748bf26c31a"
      },
      "source": [
        "!git clone https://github.com/Intelligent-Systems-Lab/Private-AI.git\n",
        "!unzip /content/Private-AI/Federated_Learning2/twitter-user-gender-classification.zip -d /content"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Private-AI'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 63 (delta 22), reused 55 (delta 16), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (63/63), done.\n",
            "Archive:  /content/Private-AI/Federated_Learning2/twitter-user-gender-classification.zip\n",
            "  inflating: /content/gender-classifier-DFE-791531.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLU6Oa1VMmDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import os\n",
        "# for dirname, _, filenames in os.walk('/content'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfUyNpMiUijv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/Private-AI/Federated_Learning\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fgx6jRDMp_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STOPWORDS = set([])  # set(stopwords.words('english'))\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = ' '.join([word for word in text.split() if word not in STOPWORDS])\n",
        "    return text\n",
        "\n",
        "def tokenize(text, word_to_idx):\n",
        "    tokens = []\n",
        "    for word in text.split():\n",
        "        tokens.append(word_to_idx[word])\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def pad_and_truncate(messages, max_length=30):\n",
        "    features = np.zeros((len(messages), max_length), dtype=int)\n",
        "    for i, sms in enumerate(messages):\n",
        "        if len(sms):\n",
        "            features[i, -len(sms):] = sms[:max_length]\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEY9bdOeNE0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/gender-classifier-DFE-791531.csv', encoding='latin-1')\n",
        "data = pd.concat([data.gender,data.description,data.text],axis=1)\n",
        "data.dropna(inplace=True,axis=0)\n",
        "data.gender = [1 if each == \"female\" else 0 for each in data.gender] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATiPtTRGNK1F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "9f84bf50-5192-4fa7-c01b-9a62062e6769"
      },
      "source": [
        "data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>description</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>i sing my own rhythm.</td>\n",
              "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>I'm the author of novels filled with family dr...</td>\n",
              "      <td>ÛÏIt felt like they were my friends and I was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>louis whining and squealing and all</td>\n",
              "      <td>i absolutely adore when louis starts the songs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Mobile guy.  49ers, Shazam, Google, Kleiner Pe...</td>\n",
              "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Ricky Wilson The Best FRONTMAN/Kaiser Chiefs T...</td>\n",
              "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20045</th>\n",
              "      <td>1</td>\n",
              "      <td>(rp)</td>\n",
              "      <td>@lookupondeath ...Fine, and I'll drink tea too...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20046</th>\n",
              "      <td>0</td>\n",
              "      <td>Whatever you like, it's not a problem at all. ...</td>\n",
              "      <td>Greg Hardy you a good player and all but don't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20047</th>\n",
              "      <td>0</td>\n",
              "      <td>#TeamBarcelona ..You look lost so you should f...</td>\n",
              "      <td>You can miss people and still never want to se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20048</th>\n",
              "      <td>1</td>\n",
              "      <td>Anti-statist; I homeschool my kids. Aspiring t...</td>\n",
              "      <td>@bitemyapp i had noticed your tendency to pee ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20049</th>\n",
              "      <td>1</td>\n",
              "      <td>Teamwork makes the dream work.</td>\n",
              "      <td>I think for my APUSH creative project I'm goin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16224 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       gender  ...                                               text\n",
              "0           0  ...  Robbie E Responds To Critics After Win Against...\n",
              "1           0  ...  ÛÏIt felt like they were my friends and I was...\n",
              "2           0  ...  i absolutely adore when louis starts the songs...\n",
              "3           0  ...  Hi @JordanSpieth - Looking at the url - do you...\n",
              "4           1  ...  Watching Neighbours on Sky+ catching up with t...\n",
              "...       ...  ...                                                ...\n",
              "20045       1  ...  @lookupondeath ...Fine, and I'll drink tea too...\n",
              "20046       0  ...  Greg Hardy you a good player and all but don't...\n",
              "20047       0  ...  You can miss people and still never want to se...\n",
              "20048       1  ...  @bitemyapp i had noticed your tendency to pee ...\n",
              "20049       1  ...  I think for my APUSH creative project I'm goin...\n",
              "\n",
              "[16224 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC9SUN_AOSxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_gender = []\n",
        "\n",
        "for t in data.gender:\n",
        "    v = np.zeros(2)\n",
        "    if t==0:\n",
        "        v[0] = 1\n",
        "    else:\n",
        "        v[1] = 1\n",
        "    data_gender.append(v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3zOSE0zOpqG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ebbd0b47-029f-461c-a095-90efa9da0654"
      },
      "source": [
        "data_gender[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1., 0.]),\n",
              " array([1., 0.]),\n",
              " array([1., 0.]),\n",
              " array([1., 0.]),\n",
              " array([0., 1.]),\n",
              " array([0., 1.]),\n",
              " array([1., 0.]),\n",
              " array([1., 0.]),\n",
              " array([0., 1.]),\n",
              " array([0., 1.])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aoYVfnwOr0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.description = data.description.apply(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auNhZhZQOxBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3eeae94b-ac84-4c30-c87a-5dde336d9d08"
      },
      "source": [
        "words = set((' '.join(data.description)).split())\n",
        "print(len(words))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tar4-7A_Ozma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_idx = {word: i for i, word in enumerate(words, 1)}\n",
        "tokens = data.description.apply(lambda x: tokenize(x, word_to_idx))\n",
        "inputs = pad_and_truncate(tokens)\n",
        "\n",
        "#labels = np.array((data.gender).astype(int))\n",
        "\n",
        "labels = np.array(data_gender)\n",
        "#labels = data.gender"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQATP2dfO2Oi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2d7013c-6c3a-4711-8245-f92886b201d7"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16224, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqfdxC-2O3p5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "83424a27-cdc5-4cd0-9194-b037c2006e60"
      },
      "source": [
        "print(inputs[:2])\n",
        "print(labels[:2])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0 15980 33188  2967 14982  8519]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0  1375  9036 14273 27735 22338\n",
            "  11875 10387 32213   786 25928 27253]]\n",
            "[[1. 0.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9iUoqhJO5-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = int(inputs.max()) + 1\n",
        "# Training params\n",
        "EPOCHS = 15\n",
        "CLIP = 5 # gradient clipping - to avoid gradient explosion (frequent in RNNs)\n",
        "lr = 0.1\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Model params\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 12\n",
        "DROPOUT = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V52AG3DnO8di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = torch.tensor(labels)\n",
        "inputs = torch.tensor(inputs)\n",
        "\n",
        "pct_test = 0.2\n",
        "\n",
        "train_labels = labels[:-int(len(labels)*pct_test)]\n",
        "train_inputs = inputs[:-int(len(labels)*pct_test)]\n",
        "\n",
        "test_labels = labels[-int(len(labels)*pct_test):]\n",
        "test_inputs = inputs[-int(len(labels)*pct_test):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zEh-NViUt9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "327cfe42-b7a9-4e1b-9f2f-5779f78e77b4"
      },
      "source": [
        "from handcrafted_GRU import GRU\n",
        "model = GRU(vocab_size=VOCAB_SIZE, output_size=2, hidden_dim=HIDDEN_DIM, embedding_dim=EMBEDDING_DIM, dropout=DROPOUT)\n",
        "model.to('cuda:0')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GRU(\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (embedding): Embedding(33673, 100)\n",
              "  (gru_cell): GRUCell(\n",
              "    (fc_ir): Linear(in_features=100, out_features=12, bias=True)\n",
              "    (fc_hr): Linear(in_features=12, out_features=12, bias=True)\n",
              "    (fc_iz): Linear(in_features=100, out_features=12, bias=True)\n",
              "    (fc_hz): Linear(in_features=12, out_features=12, bias=True)\n",
              "    (fc_in): Linear(in_features=100, out_features=12, bias=True)\n",
              "    (fc_hn): Linear(in_features=12, out_features=12, bias=True)\n",
              "  )\n",
              "  (fc): Linear(in_features=12, out_features=2, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WICaa0tJPE-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class dataset(Dataset):\n",
        "    def __init__(self, inputs, labels):\n",
        "        self.inputs =inputs\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx],self.labels[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrhromTEPHjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader = DataLoader(dataset(train_inputs,train_labels),\n",
        "                               batch_size=BATCH_SIZE, \n",
        "                               shuffle=True,\n",
        "                               num_workers=4, \n",
        "                               pin_memory=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset(test_inputs,test_labels),\n",
        "                               batch_size=BATCH_SIZE, \n",
        "                               shuffle=True,\n",
        "                               num_workers=4, \n",
        "                               pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hMCzqH0PJIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmVUG1FxPKt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch,dloader):\n",
        "    for step, (x,y) in enumerate(dloader):\n",
        "        data = Variable(x).cuda()\n",
        "        target = Variable(y).cuda()\n",
        "        h = torch.Tensor(np.zeros((BATCH_SIZE, HIDDEN_DIM))).to('cuda:0')\n",
        "        output,_ = model(data,h)\n",
        "        loss = criterion(output, target.float())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if step==0:\n",
        "            start = time.time()\n",
        "            ti = 0\n",
        "        elif step==50:\n",
        "            ti = time.time()-start #total time = ti*(length/100)\n",
        "            #print(ti)\n",
        "            ti = ti*(len(dloader)/50)\n",
        "        if step % 50 == 0:\n",
        "            second = ti*(((len(dloader)-step)/len(dloader)))#*(5-epoch)*(4-fnum)\n",
        "            print('Ep: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}\\t Remain : {} '.\n",
        "                     format(epoch+1, \n",
        "                            step * len(data), \n",
        "                            len(dloader.dataset),\n",
        "                            50.*step/len(dloader), \n",
        "                            loss.data.item(),\n",
        "                            datetime.timedelta(seconds = int(second))))\n",
        "        torch.cuda.empty_cache()\n",
        "    #print(\"Finish\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPavHX29PMeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val(dloader):\n",
        "    los = []\n",
        "    acc_num = 0\n",
        "    for step, (x, y) in enumerate(dloader):\n",
        "        data = Variable(x).cuda()\n",
        "        target = Variable(y).cuda()\n",
        "        h = torch.Tensor(np.zeros((BATCH_SIZE, HIDDEN_DIM))).to('cuda:0')\n",
        "        with torch.no_grad():\n",
        "            output,_ = model(data,h)\n",
        "        \n",
        "        loss = criterion(output, target.float())\n",
        "        los.append(loss.item())\n",
        "        \n",
        "        out = np.argmax(target.cpu().data.numpy().squeeze(),axis = 1)\n",
        "        pre = np.argmax(output.cpu().data.numpy().squeeze(),axis = 1)\n",
        "        #print(pre)\n",
        "        #print(out)\n",
        "        acc_num += (out == pre).sum()\n",
        "        \n",
        "        # if step %50 == 0:\n",
        "        #     print('[{}/{} ({:.1f}%)]'.format(step * len(data), \n",
        "        #                                 len(dloader.dataset),\n",
        "        #                                 50.*step/len(dloader)))\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "    print(\"Acc : [{}/{} ({:.1f}%)]\".format(acc_num,\n",
        "                                         len(dloader.dataset),\n",
        "                                         100.*acc_num/len(dloader.dataset)))\n",
        "    los = np.array(los)\n",
        "    avg_val_loss = los.sum()/len(los)\n",
        "    print(\"Avg val loss: {:.8f}\".format(loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buWZ_ikrPO59",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05e09b66-34bd-4d5e-fc6f-1bf0536cf674"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    if epoch %1==0:\n",
        "        lr = lr*0.9\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    model.train()\n",
        "    train(epoch, train_dataloader)\n",
        "    model.eval()\n",
        "    val(test_dataloader)\n",
        "    print(\"===============================\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Ep: 1 [0/12980 (0%)]\t Loss: 0.726588\t Remain : 0:00:00 \n",
            "Ep: 1 [6400/12980 (25%)]\t Loss: 0.719115\t Remain : 0:00:02 \n",
            "Ep: 1 [12800/12980 (49%)]\t Loss: 0.710934\t Remain : 0:00:00 \n",
            "Acc : [1862/3244 (57.4%)]\n",
            "Avg val loss: 0.71094203\n",
            "===============================\n",
            "Ep: 2 [0/12980 (0%)]\t Loss: 0.712067\t Remain : 0:00:00 \n",
            "Ep: 2 [6400/12980 (25%)]\t Loss: 0.706095\t Remain : 0:00:01 \n",
            "Ep: 2 [12800/12980 (49%)]\t Loss: 0.702237\t Remain : 0:00:00 \n",
            "Acc : [1941/3244 (59.8%)]\n",
            "Avg val loss: 0.70072275\n",
            "===============================\n",
            "Ep: 3 [0/12980 (0%)]\t Loss: 0.698231\t Remain : 0:00:00 \n",
            "Ep: 3 [6400/12980 (25%)]\t Loss: 0.700376\t Remain : 0:00:01 \n",
            "Ep: 3 [12800/12980 (49%)]\t Loss: 0.698860\t Remain : 0:00:00 \n",
            "Acc : [1950/3244 (60.1%)]\n",
            "Avg val loss: 0.69620836\n",
            "===============================\n",
            "Ep: 4 [0/12980 (0%)]\t Loss: 0.696358\t Remain : 0:00:00 \n",
            "Ep: 4 [6400/12980 (25%)]\t Loss: 0.692558\t Remain : 0:00:02 \n",
            "Ep: 4 [12800/12980 (49%)]\t Loss: 0.690425\t Remain : 0:00:00 \n",
            "Acc : [1962/3244 (60.5%)]\n",
            "Avg val loss: 0.70981836\n",
            "===============================\n",
            "Ep: 5 [0/12980 (0%)]\t Loss: 0.687259\t Remain : 0:00:00 \n",
            "Ep: 5 [6400/12980 (25%)]\t Loss: 0.690540\t Remain : 0:00:01 \n",
            "Ep: 5 [12800/12980 (49%)]\t Loss: 0.692879\t Remain : 0:00:00 \n",
            "Acc : [1961/3244 (60.5%)]\n",
            "Avg val loss: 0.69398117\n",
            "===============================\n",
            "Ep: 6 [0/12980 (0%)]\t Loss: 0.686102\t Remain : 0:00:00 \n",
            "Ep: 6 [6400/12980 (25%)]\t Loss: 0.688523\t Remain : 0:00:01 \n",
            "Ep: 6 [12800/12980 (49%)]\t Loss: 0.696709\t Remain : 0:00:00 \n",
            "Acc : [1960/3244 (60.4%)]\n",
            "Avg val loss: 0.66895521\n",
            "===============================\n",
            "Ep: 7 [0/12980 (0%)]\t Loss: 0.692399\t Remain : 0:00:00 \n",
            "Ep: 7 [6400/12980 (25%)]\t Loss: 0.682382\t Remain : 0:00:01 \n",
            "Ep: 7 [12800/12980 (49%)]\t Loss: 0.684791\t Remain : 0:00:00 \n",
            "Acc : [1961/3244 (60.5%)]\n",
            "Avg val loss: 0.69493765\n",
            "===============================\n",
            "Ep: 8 [0/12980 (0%)]\t Loss: 0.698030\t Remain : 0:00:00 \n",
            "Ep: 8 [6400/12980 (25%)]\t Loss: 0.684279\t Remain : 0:00:02 \n",
            "Ep: 8 [12800/12980 (49%)]\t Loss: 0.689384\t Remain : 0:00:00 \n",
            "Acc : [1961/3244 (60.5%)]\n",
            "Avg val loss: 0.66212541\n",
            "===============================\n",
            "Ep: 9 [0/12980 (0%)]\t Loss: 0.671744\t Remain : 0:00:00 \n",
            "Ep: 9 [6400/12980 (25%)]\t Loss: 0.694462\t Remain : 0:00:01 \n",
            "Ep: 9 [12800/12980 (49%)]\t Loss: 0.677663\t Remain : 0:00:00 \n",
            "Acc : [1961/3244 (60.5%)]\n",
            "Avg val loss: 0.69293964\n",
            "===============================\n",
            "Ep: 10 [0/12980 (0%)]\t Loss: 0.698519\t Remain : 0:00:00 \n",
            "Ep: 10 [6400/12980 (25%)]\t Loss: 0.680316\t Remain : 0:00:02 \n",
            "Ep: 10 [12800/12980 (49%)]\t Loss: 0.690212\t Remain : 0:00:00 \n",
            "Acc : [1961/3244 (60.5%)]\n",
            "Avg val loss: 0.69217652\n",
            "===============================\n",
            "Ep: 11 [0/12980 (0%)]\t Loss: 0.669543\t Remain : 0:00:00 \n",
            "Ep: 11 [6400/12980 (25%)]\t Loss: 0.683522\t Remain : 0:00:02 \n",
            "Ep: 11 [12800/12980 (49%)]\t Loss: 0.679788\t Remain : 0:00:00 \n",
            "Acc : [1961/3244 (60.5%)]\n",
            "Avg val loss: 0.71407998\n",
            "===============================\n",
            "Ep: 12 [0/12980 (0%)]\t Loss: 0.686654\t Remain : 0:00:00 \n",
            "Ep: 12 [6400/12980 (25%)]\t Loss: 0.674762\t Remain : 0:00:02 \n",
            "Ep: 12 [12800/12980 (49%)]\t Loss: 0.678709\t Remain : 0:00:00 \n",
            "Acc : [1961/3244 (60.5%)]\n",
            "Avg val loss: 0.69565374\n",
            "===============================\n",
            "Ep: 13 [0/12980 (0%)]\t Loss: 0.685712\t Remain : 0:00:00 \n",
            "Ep: 13 [6400/12980 (25%)]\t Loss: 0.679360\t Remain : 0:00:02 \n",
            "Ep: 13 [12800/12980 (49%)]\t Loss: 0.673625\t Remain : 0:00:00 \n",
            "Acc : [1961/3244 (60.5%)]\n",
            "Avg val loss: 0.68914336\n",
            "===============================\n",
            "Ep: 14 [0/12980 (0%)]\t Loss: 0.684867\t Remain : 0:00:00 \n",
            "Ep: 14 [6400/12980 (25%)]\t Loss: 0.667567\t Remain : 0:00:02 \n",
            "Ep: 14 [12800/12980 (49%)]\t Loss: 0.673642\t Remain : 0:00:00 \n",
            "Acc : [1961/3244 (60.5%)]\n",
            "Avg val loss: 0.70222652\n",
            "===============================\n",
            "Ep: 15 [0/12980 (0%)]\t Loss: 0.692138\t Remain : 0:00:00 \n",
            "Ep: 15 [6400/12980 (25%)]\t Loss: 0.681235\t Remain : 0:00:02 \n",
            "Ep: 15 [12800/12980 (49%)]\t Loss: 0.678612\t Remain : 0:00:00 \n",
            "Acc : [1961/3244 (60.5%)]\n",
            "Avg val loss: 0.72781533\n",
            "===============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1ggaqbpPVrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fetcb8V1mP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}